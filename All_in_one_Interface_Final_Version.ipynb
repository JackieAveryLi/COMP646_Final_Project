{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "yLHEi3Rka5qb"
      },
      "outputs": [],
      "source": [
        "# @title ## 1. LoRA training\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "import time\n",
        "from subprocess import getoutput\n",
        "from IPython.utils import capture\n",
        "from google.colab import drive\n",
        "\n",
        "%store -r\n",
        "\n",
        "# root_dir\n",
        "root_dir = \"/content\"\n",
        "deps_dir = os.path.join(root_dir, \"deps\")\n",
        "repo_dir = os.path.join(root_dir, \"kohya-trainer\")\n",
        "training_dir = os.path.join(root_dir, \"LoRA\")\n",
        "pretrained_model = os.path.join(root_dir, \"pretrained_model\")\n",
        "vae_dir = os.path.join(root_dir, \"vae\")\n",
        "config_dir = os.path.join(training_dir, \"config\")\n",
        "\n",
        "# repo_dir\n",
        "accelerate_config = os.path.join(repo_dir, \"accelerate_config/config.yaml\")\n",
        "tools_dir = os.path.join(repo_dir, \"tools\")\n",
        "finetune_dir = os.path.join(repo_dir, \"finetune\")\n",
        "\n",
        "for store in [\n",
        "    \"root_dir\",\n",
        "    \"deps_dir\",\n",
        "    \"repo_dir\",\n",
        "    \"training_dir\",\n",
        "    \"pretrained_model\",\n",
        "    \"vae_dir\",\n",
        "    \"accelerate_config\",\n",
        "    \"tools_dir\",\n",
        "    \"finetune_dir\",\n",
        "    \"config_dir\",\n",
        "]:\n",
        "    with capture.capture_output() as cap:\n",
        "        %store {store}\n",
        "        del cap\n",
        "\n",
        "repo_url = \"https://github.com/Linaqruf/kohya-trainer\"\n",
        "bitsandytes_main_py = \"/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py\"\n",
        "branch = \"\"  \n",
        "install_xformers = True  \n",
        "mount_drive = False  \n",
        "verbose = False \n",
        "\n",
        "def read_file(filename):\n",
        "    with open(filename, \"r\") as f:\n",
        "        contents = f.read()\n",
        "    return contents\n",
        "\n",
        "\n",
        "def write_file(filename, contents):\n",
        "    with open(filename, \"w\") as f:\n",
        "        f.write(contents)\n",
        "\n",
        "\n",
        "def clone_repo(url):\n",
        "    if not os.path.exists(repo_dir):\n",
        "        os.chdir(root_dir)\n",
        "        !git clone {url} {repo_dir}\n",
        "    else:\n",
        "        os.chdir(repo_dir)\n",
        "        !git pull origin {branch} if branch else !git pull\n",
        "\n",
        "\n",
        "def ubuntu_deps(url, name, dst):\n",
        "    !wget {'-q' if not verbose else ''} --show-progress {url}\n",
        "    with zipfile.ZipFile(name, \"r\") as deps:\n",
        "        deps.extractall(dst)\n",
        "    !dpkg -i {dst}/*\n",
        "    os.remove(name)\n",
        "    shutil.rmtree(dst)\n",
        "\n",
        "\n",
        "def install_dependencies():\n",
        "    s = getoutput('nvidia-smi')\n",
        "\n",
        "    if 'T4' in s:\n",
        "        !sed -i \"s@cpu@cuda@\" library/model_util.py\n",
        "\n",
        "    !pip {'-q' if not verbose else ''} install --upgrade -r requirements.txt\n",
        "\n",
        "    if install_xformers:\n",
        "        !pip {'-q' if not verbose else ''} install xformers==0.0.18 triton\n",
        "        \n",
        "    from accelerate.utils import write_basic_config\n",
        "\n",
        "    if not os.path.exists(accelerate_config):\n",
        "        write_basic_config(save_location=accelerate_config)\n",
        "\n",
        "\n",
        "def remove_bitsandbytes_message(filename):\n",
        "    welcome_message = \"\"\"\n",
        "def evaluate_cuda_setup():\n",
        "    print('')\n",
        "    print('='*35 + 'BUG REPORT' + '='*35)\n",
        "    print('Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues')\n",
        "    print('For effortless bug reporting copy-paste your error into this form: https://docs.google.com/forms/d/e/1FAIpQLScPB8emS3Thkp66nvqwmjTEgxp8Y9ufuWTzFyr9kJ5AoI47dQ/viewform?usp=sf_link')\n",
        "    print('='*80)\"\"\"\n",
        "\n",
        "    new_welcome_message = \"\"\"\n",
        "def evaluate_cuda_setup():\n",
        "    import os\n",
        "    if 'BITSANDBYTES_NOWELCOME' not in os.environ or str(os.environ['BITSANDBYTES_NOWELCOME']) == '0':\n",
        "        print('')\n",
        "        print('=' * 35 + 'BUG REPORT' + '=' * 35)\n",
        "        print('Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues')\n",
        "        print('For effortless bug reporting copy-paste your error into this form: https://docs.google.com/forms/d/e/1FAIpQLScPB8emS3Thkp66nvqwmjTEgxp8Y9ufuWTzFyr9kJ5AoI47dQ/viewform?usp=sf_link')\n",
        "        print('To hide this message, set the BITSANDBYTES_NOWELCOME variable like so: export BITSANDBYTES_NOWELCOME=1')\n",
        "        print('=' * 80)\"\"\"\n",
        "\n",
        "    contents = read_file(filename)\n",
        "    new_contents = contents.replace(welcome_message, new_welcome_message)\n",
        "    write_file(filename, new_contents)\n",
        "\n",
        "\n",
        "def main():\n",
        "    os.chdir(root_dir)\n",
        "\n",
        "    if mount_drive:\n",
        "        if not os.path.exists(\"/content/drive\"):\n",
        "            drive.mount(\"/content/drive\")\n",
        "\n",
        "    for dir in [\n",
        "        deps_dir, \n",
        "        training_dir, \n",
        "        config_dir, \n",
        "        pretrained_model, \n",
        "        vae_dir\n",
        "    ]:\n",
        "        os.makedirs(dir, exist_ok=True)\n",
        "\n",
        "    clone_repo(repo_url)\n",
        "\n",
        "    if branch:\n",
        "        os.chdir(repo_dir)\n",
        "        status = os.system(f\"git checkout {branch}\")\n",
        "        if status != 0:\n",
        "            raise Exception(\"Failed to checkout branch or commit\")\n",
        "\n",
        "    os.chdir(repo_dir)\n",
        "    \n",
        "    !apt -y update {'-qq' if not verbose else ''}\n",
        "    !apt install libunwind8-dev {'-qq' if not verbose else ''}\n",
        "\n",
        "    ubuntu_deps(\n",
        "        \"https://huggingface.co/Linaqruf/fast-repo/resolve/main/deb-libs.zip\",\n",
        "        \"deb-libs.zip\",\n",
        "        deps_dir,\n",
        "    )\n",
        "\n",
        "    install_dependencies()\n",
        "    time.sleep(3)\n",
        "    \n",
        "    remove_bitsandbytes_message(bitsandytes_main_py)\n",
        "\n",
        "    os.environ[\"LD_PRELOAD\"] = \"libtcmalloc.so\"\n",
        "    os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "    os.environ[\"BITSANDBYTES_NOWELCOME\"] = \"1\"  \n",
        "    os.environ[\"SAFETENSORS_FAST_GPU\"] = \"1\"\n",
        "\n",
        "    cuda_path = \"/usr/local/cuda-11.8/targets/x86_64-linux/lib/\"\n",
        "    ld_library_path = os.environ.get(\"LD_LIBRARY_PATH\", \"\")\n",
        "    os.environ[\"LD_LIBRARY_PATH\"] = f\"{ld_library_path}:{cuda_path}\"\n",
        "\n",
        "main()\n",
        "\n",
        "print(\"we are here!\")\n",
        "\n",
        "import threading\n",
        "from google.colab import output\n",
        "from imjoy_elfinder.app import main\n",
        "\n",
        "open_in_new_tab = True\n",
        "\n",
        "def start_file_explorer(root_dir=root_dir, port=8765):\n",
        "    try:\n",
        "        main([\"--root-dir=\" + root_dir, \"--port=\" + str(port)])\n",
        "    except Exception as e:\n",
        "        print(\"Error starting file explorer:\", str(e))\n",
        "\n",
        "\n",
        "def open_file_explorer(open_in_new_tab=False, root_dir=root_dir, port=8765):\n",
        "    thread = threading.Thread(target=start_file_explorer, args=[root_dir, port])\n",
        "    thread.start()\n",
        "\n",
        "    if open_in_new_tab:\n",
        "        output.serve_kernel_port_as_window(port)\n",
        "    else:\n",
        "        output.serve_kernel_port_as_iframe(port, height=\"500\")\n",
        "\n",
        "open_file_explorer(open_in_new_tab=open_in_new_tab, root_dir=root_dir, port=8765)\n",
        "\n",
        "import os\n",
        "\n",
        "%store -r\n",
        "\n",
        "os.chdir(root_dir)\n",
        "\n",
        "models = {\n",
        "    \"Animefull-final-pruned\": \"https://huggingface.co/Linaqruf/personal-backup/resolve/main/models/animefull-final-pruned.ckpt\",\n",
        "    \"Anything-v3-1\": \"https://huggingface.co/cag/anything-v3-1/resolve/main/anything-v3-1.safetensors\",\n",
        "    \"AnyLoRA\": \"https://huggingface.co/Lykon/AnyLoRA/resolve/main/AnyLoRA_bakedVae_fp16_NOTpruned.safetensors\",\n",
        "    \"AnimePastelDream\": \"https://huggingface.co/Lykon/AnimePastelDream/resolve/main/AnimePastelDream_Soft_noVae_fp16.safetensors\",\n",
        "    \"Chillout-mix\": \"https://huggingface.co/Linaqruf/stolen/resolve/main/pruned-models/chillout_mix-pruned.safetensors\",\n",
        "    \"OpenJourney-v4\": \"https://huggingface.co/prompthero/openjourney-v4/resolve/main/openjourney-v4.ckpt\",\n",
        "    \"Stable-Diffusion-v1-5\": \"https://huggingface.co/Linaqruf/stolen/resolve/main/pruned-models/stable_diffusion_1_5-pruned.safetensors\",\n",
        "}\n",
        "\n",
        "installModels = []\n",
        "\n",
        "model_name = \"Stable-Diffusion-v1-5\" # @param [\"\", \"Animefull-final-pruned\", \"Anything-v3-1\", \"AnyLoRA\", \"AnimePastelDream\", \"Chillout-mix\", \"OpenJourney-v4\", \"Stable-Diffusion-v1-5\"]\n",
        "\n",
        "if model_name:\n",
        "    model_url = models.get(model_name)\n",
        "    if model_url:\n",
        "        installModels.append((model_name, model_url))\n",
        "\n",
        "def install(checkpoint_name, url):\n",
        "    ext = \"ckpt\" if url.endswith(\".ckpt\") else \"safetensors\"\n",
        "\n",
        "    hf_token = \"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\"\n",
        "    user_header = f'\"Authorization: Bearer {hf_token}\"'\n",
        "    !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {pretrained_model} -o {checkpoint_name}.{ext} \"{url}\"\n",
        "\n",
        "\n",
        "def install_checkpoint():\n",
        "    for model in installModels:\n",
        "        install(model[0], model[1])\n",
        "    \n",
        "\n",
        "\n",
        "install_checkpoint()\n",
        "\n",
        "import os\n",
        "\n",
        "%store -r\n",
        "\n",
        "os.chdir(root_dir)\n",
        "\n",
        "vaes = {\n",
        "    \"none\": \"\",\n",
        "    \"anime.vae.pt\": \"https://huggingface.co/Linaqruf/personal-backup/resolve/main/vae/animevae.pt\",\n",
        "    \"waifudiffusion.vae.pt\": \"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime.ckpt\",\n",
        "    \"stablediffusion.vae.pt\": \"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.ckpt\",\n",
        "}\n",
        "install_vaes = []\n",
        "\n",
        "\n",
        "vae_name = \"anime.vae.pt\"  \n",
        "if vae_name in vaes:\n",
        "    vae_url = vaes[vae_name]\n",
        "    if vae_url:\n",
        "        install_vaes.append((vae_name, vae_url))\n",
        "\n",
        "\n",
        "def install(vae_name, url):\n",
        "    hf_token = \"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\"\n",
        "    user_header = f'\"Authorization: Bearer {hf_token}\"'\n",
        "    !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {vae_dir} -o {vae_name} \"{url}\"\n",
        "\n",
        "\n",
        "def install_vae():\n",
        "    for vae in install_vaes:\n",
        "        install(vae[0], vae[1])\n",
        "\n",
        "\n",
        "install_vae()\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "v2 = False  \n",
        "v_parameterization = False  \n",
        "project_name = \"moshe_face\" # @param {type:\"string\"}\n",
        "\n",
        "%store project_name\n",
        "\n",
        "pretrained_model_name_or_path = \"/content/pretrained_model/Stable-Diffusion-v1-5.safetensors\"\n",
        "\n",
        "vae = \"/content/vae/anime.vae.pt\"  \n",
        "output_dir = \"/content/LoRA/output\"\n",
        "\n",
        "output_to_drive = False  \n",
        "\n",
        "if output_to_drive:\n",
        "    output_dir = \"/content/drive/MyDrive/LoRA/output\"\n",
        "\n",
        "    if not os.path.exists(\"/content/drive\"):\n",
        "        drive.mount(\"/content/drive\")\n",
        "\n",
        "sample_dir = os.path.join(output_dir, \"sample\")\n",
        "for dir in [output_dir, sample_dir]:\n",
        "    os.makedirs(dir, exist_ok=True)\n",
        "\n",
        "print(\"Project Name: \", project_name)\n",
        "print(\"Model Version: Stable Diffusion V1.x\") if not v2 else \"\"\n",
        "print(\"Model Version: Stable Diffusion V2.x\") if v2 and not v_parameterization else \"\"\n",
        "print(\"Model Version: Stable Diffusion V2.x 768v\") if v2 and v_parameterization else \"\"\n",
        "print(\n",
        "    \"Pretrained Model Path: \", pretrained_model_name_or_path\n",
        ") if pretrained_model_name_or_path else print(\"No Pretrained Model path specified.\")\n",
        "print(\"VAE Path: \", vae) if vae else print(\"No VAE path specified.\")\n",
        "print(\"Output Path: \", output_dir)\n",
        "\n",
        "import os\n",
        "from IPython.utils import capture\n",
        "\n",
        "%store -r\n",
        "\n",
        "\n",
        "train_data_dir = \"\"  \n",
        "reg_data_dir = \"/content/LoRA/reg_data\"  \n",
        "\n",
        "for dir in [train_data_dir, reg_data_dir]:\n",
        "    if dir:\n",
        "        with capture.capture_output() as cap:\n",
        "            os.makedirs(dir, exist_ok=True)\n",
        "            %store dir\n",
        "            del cap\n",
        "if train_data_dir:\n",
        "  print(f\"Your train data directory : {train_data_dir}\")\n",
        "if reg_data_dir:\n",
        "    print(f\"Your reg data directory : {reg_data_dir}\")\n",
        "\n",
        "url = 'https://drive.google.com/file/d/1MckW8NnlXvQA8tJlKsdYZk7QITuvEAd_' # @param {type:\"string\"}\n",
        "filename = \"alt\" # @param {type:\"string\"}\n",
        "zipfilename = \"/content/\"+filename+\".zip\"\n",
        "\n",
        "#!gdown {url}\n",
        "lora_path = \"/content/LoRA\"\n",
        "fileid = url.split(\"/file/d/\",1)[1] + \"&confirm=t\"\n",
        "\n",
        "!gdown -q {fileid}\n",
        "!unzip {zipfilename} -d {lora_path}\n",
        "\n",
        "oldname =\"/content/LoRA/\"+filename\n",
        "train_data_dir = \"/content/LoRA/train_data\"\n",
        "\n",
        "os.rename(oldname,train_data_dir)\n",
        "\n",
        "import toml\n",
        "import glob\n",
        "\n",
        "\n",
        "dataset_repeats = 10  \n",
        "\n",
        "activation_word = \"mksks style\"  \n",
        "caption_extension = \".txt\"  \n",
        "\n",
        "token_to_captions = False  \n",
        "resolution = 512  \n",
        "flip_aug = False  \n",
        "keep_tokens = 0 \n",
        "\n",
        "if ',' in activation_word or ' ' in activation_word:\n",
        "    words = activation_word.replace(',', ' ').split()\n",
        "    class_token = words[-1]\n",
        "\n",
        "\n",
        "def read_file(filename):\n",
        "    with open(filename, \"r\") as f:\n",
        "        contents = f.read()\n",
        "    return contents\n",
        "\n",
        "\n",
        "def write_file(filename, contents):\n",
        "    with open(filename, \"w\") as f:\n",
        "        f.write(contents)\n",
        "\n",
        "\n",
        "def get_supported_images(folder):\n",
        "    supported_extensions = (\".png\", \".jpg\", \".jpeg\", \".webp\", \".bmp\")\n",
        "    return [file for ext in supported_extensions for file in glob.glob(f\"{folder}/*{ext}\")]\n",
        "\n",
        "\n",
        "def get_subfolders_with_supported_images(folder):\n",
        "    subfolders = [os.path.join(folder, subfolder) for subfolder in os.listdir(folder) if os.path.isdir(os.path.join(folder, subfolder))]\n",
        "    return [subfolder for subfolder in subfolders if len(get_supported_images(subfolder)) > 0]\n",
        "\n",
        "\n",
        "def process_tags(filename, custom_tag, remove_tag):\n",
        "    contents = read_file(filename)\n",
        "    tags = [tag.strip() for tag in contents.split(',')]\n",
        "    custom_tags = [tag.strip() for tag in custom_tag.split(',')]\n",
        "\n",
        "    for custom_tag in custom_tags:\n",
        "        custom_tag = custom_tag.replace(\"_\", \" \")\n",
        "        if remove_tag:\n",
        "            while custom_tag in tags:\n",
        "                tags.remove(custom_tag)\n",
        "        else:\n",
        "            if custom_tag not in tags:\n",
        "                tags.insert(0, custom_tag)\n",
        "\n",
        "    contents = ', '.join(tags)\n",
        "    write_file(filename, contents)\n",
        "\n",
        "\n",
        "def process_folder_recursively(folder):\n",
        "    for root, _, files in os.walk(folder):\n",
        "        for file in files:\n",
        "            if file.endswith(caption_extension):\n",
        "                file_path = os.path.join(root, file)\n",
        "                extracted_class_token = get_class_token_from_folder_name(root, folder)\n",
        "                train_supported_images = get_supported_images(train_data_dir)\n",
        "                tag = extracted_class_token if extracted_class_token else activation_word if train_supported_images else \"\"\n",
        "                if not tag == \"\":\n",
        "                    process_tags(file_path, tag, remove_tag=(not token_to_captions))\n",
        "\n",
        "\n",
        "def get_num_repeats(folder):\n",
        "    folder_name = os.path.basename(folder)\n",
        "    try:\n",
        "        repeats, _ = folder_name.split('_', 1)\n",
        "        num_repeats = int(repeats)\n",
        "    except ValueError:\n",
        "        num_repeats = 1\n",
        "\n",
        "    return num_repeats\n",
        "\n",
        "\n",
        "def get_class_token_from_folder_name(folder, parent_folder):\n",
        "    if folder == parent_folder:\n",
        "        return class_token\n",
        "\n",
        "    folder_name = os.path.basename(folder)\n",
        "    try:\n",
        "        _, concept = folder_name.split('_', 1)\n",
        "        return concept\n",
        "    except ValueError:\n",
        "        return \"\"\n",
        "        \n",
        "train_supported_images = get_supported_images(train_data_dir)\n",
        "train_subfolders = get_subfolders_with_supported_images(train_data_dir)\n",
        "reg_supported_images = get_supported_images(reg_data_dir)\n",
        "reg_subfolders = get_subfolders_with_supported_images(reg_data_dir)\n",
        "\n",
        "subsets = []\n",
        "\n",
        "config = {\n",
        "    \"general\": {\n",
        "        \"enable_bucket\": True,\n",
        "        \"caption_extension\": caption_extension,\n",
        "        \"shuffle_caption\": True,\n",
        "        \"keep_tokens\": keep_tokens,\n",
        "        \"bucket_reso_steps\": 64,\n",
        "        \"bucket_no_upscale\": False,\n",
        "    },\n",
        "    \"datasets\": [\n",
        "        {\n",
        "            \"resolution\": resolution,\n",
        "            \"min_bucket_reso\": 320 if resolution > 640 else 256,\n",
        "            \"max_bucket_reso\": 1280 if resolution > 640 else 1024,\n",
        "            \"caption_dropout_rate\": 0,\n",
        "            \"caption_tag_dropout_rate\": 0,\n",
        "            \"caption_dropout_every_n_epochs\": 0,\n",
        "            \"flip_aug\": flip_aug,\n",
        "            \"color_aug\": False,\n",
        "            \"face_crop_aug_range\": None,\n",
        "            \"subsets\": subsets,\n",
        "        }\n",
        "    ],\n",
        "}\n",
        "\n",
        "if token_to_captions and keep_tokens < 2:\n",
        "    keep_tokens = 1\n",
        "\n",
        "if caption_extension != \"none\":\n",
        "    process_folder_recursively(train_data_dir)\n",
        "\n",
        "if train_supported_images:\n",
        "    subsets.append({\n",
        "        \"image_dir\": train_data_dir,\n",
        "        \"class_tokens\": activation_word,\n",
        "        \"num_repeats\": dataset_repeats,\n",
        "    })\n",
        "\n",
        "for subfolder in train_subfolders:\n",
        "    num_repeats = get_num_repeats(subfolder)\n",
        "    extracted_class_token = get_class_token_from_folder_name(subfolder, train_data_dir)\n",
        "    subsets.append({\n",
        "        \"image_dir\": subfolder,\n",
        "        \"class_tokens\": extracted_class_token if extracted_class_token else None,\n",
        "        \"num_repeats\": num_repeats,\n",
        "    })\n",
        "\n",
        "if reg_supported_images:\n",
        "    subsets.append({\n",
        "        \"is_reg\": True,\n",
        "        \"image_dir\": reg_data_dir,\n",
        "        \"class_tokens\": class_token if 'class_token' in globals() else None,\n",
        "        \"num_repeats\": 1,\n",
        "    })\n",
        "\n",
        "for subfolder in reg_subfolders:\n",
        "    extracted_class_token = get_class_token_from_folder_name(subfolder, reg_data_dir)\n",
        "    subsets.append({\n",
        "        \"is_reg\": True,\n",
        "        \"image_dir\": subfolder,\n",
        "        \"class_tokens\": extracted_class_token if extracted_class_token else None,\n",
        "        \"num_repeats\": num_repeats,\n",
        "    })\n",
        "\n",
        "for subset in subsets:\n",
        "    if not glob.glob(f\"{subset['image_dir']}/*.txt\"):\n",
        "        subset[\"class_tokens\"] = activation_word\n",
        "\n",
        "dataset_config = os.path.join(config_dir, \"dataset_config.toml\")\n",
        "\n",
        "for key in config:\n",
        "    if isinstance(config[key], dict):\n",
        "        for sub_key in config[key]:\n",
        "            if config[key][sub_key] == \"\":\n",
        "                config[key][sub_key] = None\n",
        "    elif config[key] == \"\":\n",
        "        config[key] = None\n",
        "\n",
        "config_str = toml.dumps(config)\n",
        "\n",
        "with open(dataset_config, \"w\") as f:\n",
        "    f.write(config_str)\n",
        "\n",
        "print(config_str)\n",
        "\n",
        "\n",
        "network_category = \"LoRA\"  \n",
        "conv_dim = 32  \n",
        "conv_alpha = 16  \n",
        "network_dim = 32  \n",
        "network_alpha = 16  \n",
        "\n",
        "network_weight = \"\"  \n",
        "network_module = \"lycoris.kohya\" if network_category in [\"LoHa\", \"LoCon_Lycoris\"] else \"networks.lora\"\n",
        "network_args = \"\" if network_category == \"LoRA\" else [\n",
        "    f\"conv_dim={conv_dim}\", f\"conv_alpha={conv_alpha}\",\n",
        "    ]\n",
        "min_snr_gamma = -1 \n",
        "optimizer_type = \"AdamW8bit\"  # @param [\"AdamW\", \"AdamW8bit\", \"Lion\", \"SGDNesterov\", \"SGDNesterov8bit\", \"DAdaptation\", \"AdaFactor\"]\n",
        "\n",
        "optimizer_args = \"\"  \n",
        "train_unet = True  \n",
        "unet_lr = 1e-4  \n",
        "train_text_encoder = True  \n",
        "text_encoder_lr = 5e-5  \n",
        "lr_scheduler = \"constant\"  \n",
        "lr_warmup_steps = 0  \n",
        "lr_scheduler_num_cycles = 0 \n",
        "lr_scheduler_power = 0  #\n",
        "\n",
        "if network_category == \"LoHa\":\n",
        "  network_args.append(\"algo=loha\")\n",
        "elif network_category == \"LoCon_Lycoris\":\n",
        "  network_args.append(\"algo=lora\")\n",
        "\n",
        "print(\"- LoRA Config:\")\n",
        "print(f\"  - Min-SNR Weighting: {min_snr_gamma}\") if not min_snr_gamma == -1 else \"\"\n",
        "print(f\"  - Loading network module: {network_module}\")\n",
        "if not network_category == \"LoRA\":\n",
        "  print(f\"  - network args: {network_args}\")\n",
        "print(f\"  - {network_module} linear_dim set to: {network_dim}\")\n",
        "print(f\"  - {network_module} linear_alpha set to: {network_alpha}\")\n",
        "if not network_category == \"LoRA\":\n",
        "  print(f\"  - {network_module} conv_dim set to: {conv_dim}\")\n",
        "  print(f\"  - {network_module} conv_alpha set to: {conv_alpha}\")\n",
        "\n",
        "if not network_weight:\n",
        "    print(\"  - No LoRA weight loaded.\")\n",
        "else:\n",
        "    if os.path.exists(network_weight):\n",
        "        print(f\"  - Loading LoRA weight: {network_weight}\")\n",
        "    else:\n",
        "        print(f\"  - {network_weight} does not exist.\")\n",
        "        network_weight = \"\"\n",
        "\n",
        "print(\"- Optimizer Config:\")\n",
        "print(f\"  - Additional network category: {network_category}\")\n",
        "print(f\"  - Using {optimizer_type} as Optimizer\")\n",
        "if optimizer_args:\n",
        "    print(f\"  - Optimizer Args: {optimizer_args}\")\n",
        "if train_unet and train_text_encoder:\n",
        "    print(\"  - Train UNet and Text Encoder\")\n",
        "    print(f\"    - UNet learning rate: {unet_lr}\")\n",
        "    print(f\"    - Text encoder learning rate: {text_encoder_lr}\")\n",
        "if train_unet and not train_text_encoder:\n",
        "    print(\"  - Train UNet only\")\n",
        "    print(f\"    - UNet learning rate: {unet_lr}\")\n",
        "if train_text_encoder and not train_unet:\n",
        "    print(\"  - Train Text Encoder only\")\n",
        "    print(f\"    - Text encoder learning rate: {text_encoder_lr}\")\n",
        "print(f\"  - Learning rate warmup steps: {lr_warmup_steps}\")\n",
        "print(f\"  - Learning rate Scheduler: {lr_scheduler}\")\n",
        "if lr_scheduler == \"cosine_with_restarts\":\n",
        "    print(f\"  - lr_scheduler_num_cycles: {lr_scheduler_num_cycles}\")\n",
        "elif lr_scheduler == \"polynomial\":\n",
        "    print(f\"  - lr_scheduler_power: {lr_scheduler_power}\")\n",
        "\n",
        "import toml\n",
        "import os\n",
        "\n",
        "%store -r\n",
        "lowram = True  \n",
        "enable_sample_prompt = True  \n",
        "sampler = \"heun\"  # @param [\"ddim\", \"pndm\", \"lms\", \"euler\", \"euler_a\", \"heun\", \"dpm_2\", \"dpm_2_a\", \"dpmsolver\",\"dpmsolver++\", \"dpmsingle\", \"k_lms\", \"k_euler\", \"k_euler_a\", \"k_dpm_2\", \"k_dpm_2_a\"]\n",
        "noise_offset = 0  # @param {type:\"number\"}\n",
        "num_epochs = 100  # @param {type:\"number\"}\n",
        "vae_batch_size = 4  \n",
        "train_batch_size = 6  \n",
        "mixed_precision = \"fp16\"  \n",
        "save_precision = \"fp16\"  \n",
        "save_n_epochs_type = \"save_every_n_epochs\"  \n",
        "save_n_epochs_type_value = 1  \n",
        "save_model_as = \"safetensors\"  \n",
        "max_token_length = 225 \n",
        "clip_skip = 2 \n",
        "gradient_checkpointing = False \n",
        "gradient_accumulation_steps = 1 \n",
        "seed = -1  \n",
        "logging_dir = \"/content/LoRA/logs\"\n",
        "prior_loss_weight = 1.0\n",
        "\n",
        "os.chdir(repo_dir)\n",
        "\n",
        "sample_str = f\"\"\"\n",
        "  masterpiece, best quality, 1girl, aqua eyes, baseball cap, blonde hair, closed mouth, earrings, green background, hat, hoop earrings, jewelry, looking at viewer, shirt, short hair, simple background, solo, upper body, yellow shirt \\\n",
        "  --n lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry \\\n",
        "  --w 512 \\\n",
        "  --h 768 \\\n",
        "  --l 7 \\\n",
        "  --s 28    \n",
        "\"\"\"\n",
        "\n",
        "config = {\n",
        "    \"model_arguments\": {\n",
        "        \"v2\": v2,\n",
        "        \"v_parameterization\": v_parameterization if v2 and v_parameterization else False,\n",
        "        \"pretrained_model_name_or_path\": pretrained_model_name_or_path,\n",
        "        \"vae\": vae,\n",
        "    },\n",
        "    \"additional_network_arguments\": {\n",
        "        \"no_metadata\": False,\n",
        "        \"unet_lr\": float(unet_lr) if train_unet else None,\n",
        "        \"text_encoder_lr\": float(text_encoder_lr) if train_text_encoder else None,\n",
        "        \"network_weights\": network_weight,\n",
        "        \"network_module\": network_module,\n",
        "        \"network_dim\": network_dim,\n",
        "        \"network_alpha\": network_alpha,\n",
        "        \"network_args\": network_args,\n",
        "        \"network_train_unet_only\": True if train_unet and not train_text_encoder else False,\n",
        "        \"network_train_text_encoder_only\": True if train_text_encoder and not train_unet else False,\n",
        "        \"training_comment\": None,\n",
        "    },\n",
        "    \"optimizer_arguments\": {\n",
        "        \"min_snr_gamma\": min_snr_gamma if not min_snr_gamma == -1 else None,\n",
        "        \"optimizer_type\": optimizer_type,\n",
        "        \"learning_rate\": unet_lr,\n",
        "        \"max_grad_norm\": 1.0,\n",
        "        \"optimizer_args\": eval(optimizer_args) if optimizer_args else None,\n",
        "        \"lr_scheduler\": lr_scheduler,\n",
        "        \"lr_warmup_steps\": lr_warmup_steps,\n",
        "        \"lr_scheduler_num_cycles\": lr_scheduler_num_cycles if lr_scheduler == \"cosine_with_restarts\" else None,\n",
        "        \"lr_scheduler_power\": lr_scheduler_power if lr_scheduler == \"polynomial\" else None,\n",
        "    },\n",
        "    \"dataset_arguments\": {\n",
        "        \"cache_latents\": True,\n",
        "        \"debug_dataset\": False,\n",
        "        \"vae_batch_size\": vae_batch_size,\n",
        "    },\n",
        "    \"training_arguments\": {\n",
        "        \"output_dir\": output_dir,\n",
        "        \"output_name\": project_name,\n",
        "        \"save_precision\": save_precision,\n",
        "        \"save_every_n_epochs\": save_n_epochs_type_value if save_n_epochs_type == \"save_every_n_epochs\" else None,\n",
        "        \"save_n_epoch_ratio\": save_n_epochs_type_value if save_n_epochs_type == \"save_n_epoch_ratio\" else None,\n",
        "        \"save_last_n_epochs\": None,\n",
        "        \"save_state\": None,\n",
        "        \"save_last_n_epochs_state\": None,\n",
        "        \"resume\": None,\n",
        "        \"train_batch_size\": train_batch_size,\n",
        "        \"max_token_length\": 225,\n",
        "        \"mem_eff_attn\": False,\n",
        "        \"xformers\": True,\n",
        "        \"max_train_epochs\": num_epochs,\n",
        "        \"max_data_loader_n_workers\": 8,\n",
        "        \"persistent_data_loader_workers\": True,\n",
        "        \"seed\": seed if seed > 0 else None,\n",
        "        \"gradient_checkpointing\": gradient_checkpointing,\n",
        "        \"gradient_accumulation_steps\": gradient_accumulation_steps,\n",
        "        \"mixed_precision\": mixed_precision,\n",
        "        \"clip_skip\": clip_skip if not v2 else None,\n",
        "        \"logging_dir\": logging_dir,\n",
        "        \"log_prefix\": project_name,\n",
        "        \"noise_offset\": noise_offset if noise_offset > 0 else None,\n",
        "        \"lowram\": lowram,\n",
        "    },\n",
        "    \"sample_prompt_arguments\": {\n",
        "        \"sample_every_n_steps\": None,\n",
        "        \"sample_every_n_epochs\": 1 if enable_sample_prompt else 999999,\n",
        "        \"sample_sampler\": sampler,\n",
        "    },\n",
        "    \"dreambooth_arguments\": {\n",
        "        \"prior_loss_weight\": 1.0,\n",
        "    },\n",
        "    \"saving_arguments\": {\n",
        "        \"save_model_as\": save_model_as\n",
        "    },\n",
        "}\n",
        "\n",
        "config_path = os.path.join(config_dir, \"config_file.toml\")\n",
        "prompt_path = os.path.join(config_dir, \"sample_prompt.txt\")\n",
        "\n",
        "for key in config:\n",
        "    if isinstance(config[key], dict):\n",
        "        for sub_key in config[key]:\n",
        "            if config[key][sub_key] == \"\":\n",
        "                config[key][sub_key] = None\n",
        "    elif config[key] == \"\":\n",
        "        config[key] = None\n",
        "\n",
        "config_str = toml.dumps(config)\n",
        "\n",
        "def write_file(filename, contents):\n",
        "    with open(filename, \"w\") as f:\n",
        "        f.write(contents)\n",
        "\n",
        "write_file(config_path, config_str)\n",
        "write_file(prompt_path, sample_str)\n",
        "    \n",
        "print(config_str)\n",
        "\n",
        "sample_prompt = \"/content/LoRA/config/sample_prompt.txt\" \n",
        "config_file = \"/content/LoRA/config/config_file.toml\" \n",
        "dataset_config = \"/content/LoRA/config/dataset_config.toml\" \n",
        "\n",
        "accelerate_conf = {\n",
        "    \"config_file\" : accelerate_config,\n",
        "    \"num_cpu_threads_per_process\" : 1,\n",
        "}\n",
        "\n",
        "train_conf = {\n",
        "    \"sample_prompts\" : sample_prompt,\n",
        "    \"dataset_config\" : dataset_config,\n",
        "    \"config_file\" : config_file\n",
        "}\n",
        "\n",
        "def train(config):\n",
        "    args = \"\"\n",
        "    for k, v in config.items():\n",
        "        if k.startswith(\"_\"):\n",
        "            args += f'\"{v}\" '\n",
        "        elif isinstance(v, str):\n",
        "            args += f'--{k}=\"{v}\" '\n",
        "        elif isinstance(v, bool) and v:\n",
        "            args += f\"--{k} \"\n",
        "        elif isinstance(v, float) and not isinstance(v, bool):\n",
        "            args += f\"--{k}={v} \"\n",
        "        elif isinstance(v, int) and not isinstance(v, bool):\n",
        "            args += f\"--{k}={v} \"\n",
        "\n",
        "    return args\n",
        "\n",
        "accelerate_args = train(accelerate_conf)\n",
        "train_args = train(train_conf)\n",
        "final_args = f\"accelerate launch {accelerate_args} train_network.py {train_args}\"\n",
        "\n",
        "os.chdir(repo_dir)\n",
        "!{final_args}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## 2. Inference on Stable Diffusion(Open Web GUI by Gradio)\n",
        "import shutil\n",
        "\n",
        "#@markdown Choose your stable diffusion model\n",
        "\n",
        "model_name = \"Stable-Diffusion-v1-5\" # @param [\"\", \"Anything-v3-1\", \"AnyLoRA\", \"AnimePastelDream\", \"Chillout-mix\", \"OpenJourney-v4\", \"Stable-Diffusion-v1-5\"]\n",
        "\n",
        "#@markdown Add the trained LoRA model to the GUI\n",
        "\n",
        "trained_model_name = \"moshe_face\" # @param {type:\"string\"}\n",
        "\n",
        "%cd /content\n",
        "\n",
        "%env TF_CPP_MIN_LOG_LEVEL=1\n",
        "\n",
        "!apt -y update -qq\n",
        "!wget http://launchpadlibrarian.net/367274644/libgoogle-perftools-dev_2.5-2.2ubuntu3_amd64.deb\n",
        "!wget https://launchpad.net/ubuntu/+source/google-perftools/2.5-2.2ubuntu3/+build/14795286/+files/google-perftools_2.5-2.2ubuntu3_all.deb\n",
        "!wget https://launchpad.net/ubuntu/+source/google-perftools/2.5-2.2ubuntu3/+build/14795286/+files/libtcmalloc-minimal4_2.5-2.2ubuntu3_amd64.deb\n",
        "!wget https://launchpad.net/ubuntu/+source/google-perftools/2.5-2.2ubuntu3/+build/14795286/+files/libgoogle-perftools4_2.5-2.2ubuntu3_amd64.deb\n",
        "!apt install -qq libunwind8-dev\n",
        "!dpkg -i *.deb\n",
        "%env LD_PRELOAD=libtcmalloc.so\n",
        "!rm *.deb\n",
        "\n",
        "!apt -y install -qq aria2\n",
        "!pip install -q torch==1.13.1+cu116 torchvision==0.14.1+cu116 torchaudio==0.13.1 torchtext==0.14.1 torchdata==0.5.1 --extra-index-url https://download.pytorch.org/whl/cu116 -U\n",
        "!pip install -q xformers==0.0.16 triton==2.0.0 -U\n",
        "\n",
        "!git clone -b v2.1 https://github.com/camenduru/stable-diffusion-webui\n",
        "!git clone https://huggingface.co/embed/negative /content/stable-diffusion-webui/embeddings/negative\n",
        "!git clone https://huggingface.co/embed/lora /content/stable-diffusion-webui/models/Lora/positive\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/embed/upscale/resolve/main/4x-UltraSharp.pth -d /content/stable-diffusion-webui/models/ESRGAN -o 4x-UltraSharp.pth\n",
        "!wget https://raw.githubusercontent.com/camenduru/stable-diffusion-webui-scripts/main/run_n_times.py -O /content/stable-diffusion-webui/scripts/run_n_times.py\n",
        "!git clone https://github.com/deforum-art/deforum-for-automatic1111-webui /content/stable-diffusion-webui/extensions/deforum-for-automatic1111-webui\n",
        "!git clone https://github.com/camenduru/stable-diffusion-webui-images-browser /content/stable-diffusion-webui/extensions/stable-diffusion-webui-images-browser\n",
        "!git clone https://github.com/camenduru/stable-diffusion-webui-huggingface /content/stable-diffusion-webui/extensions/stable-diffusion-webui-huggingface\n",
        "!git clone https://github.com/camenduru/sd-civitai-browser /content/stable-diffusion-webui/extensions/sd-civitai-browser\n",
        "!git clone https://github.com/kohya-ss/sd-webui-additional-networks /content/stable-diffusion-webui/extensions/sd-webui-additional-networks\n",
        "!git clone https://github.com/Mikubill/sd-webui-controlnet /content/stable-diffusion-webui/extensions/sd-webui-controlnet\n",
        "!git clone https://github.com/fkunn1326/openpose-editor /content/stable-diffusion-webui/extensions/openpose-editor\n",
        "!git clone https://github.com/jexom/sd-webui-depth-lib /content/stable-diffusion-webui/extensions/sd-webui-depth-lib\n",
        "!git clone https://github.com/hnmr293/posex /content/stable-diffusion-webui/extensions/posex\n",
        "!git clone https://github.com/nonnonstop/sd-webui-3d-open-pose-editor /content/stable-diffusion-webui/extensions/sd-webui-3d-open-pose-editor\n",
        "!git clone https://github.com/camenduru/sd-webui-tunnels /content/stable-diffusion-webui/extensions/sd-webui-tunnels\n",
        "!git clone https://github.com/etherealxx/batchlinks-webui /content/stable-diffusion-webui/extensions/batchlinks-webui\n",
        "!git clone https://github.com/camenduru/stable-diffusion-webui-catppuccin /content/stable-diffusion-webui/extensions/stable-diffusion-webui-catppuccin\n",
        "!git clone https://github.com/KohakuBlueleaf/a1111-sd-webui-locon /content/stable-diffusion-webui/extensions/a1111-sd-webui-locon\n",
        "!git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui-rembg /content/stable-diffusion-webui/extensions/stable-diffusion-webui-rembg\n",
        "!git clone https://github.com/ashen-sensored/stable-diffusion-webui-two-shot /content/stable-diffusion-webui/extensions/stable-diffusion-webui-two-shot\n",
        "!git clone https://github.com/camenduru/sd_webui_stealth_pnginfo /content/stable-diffusion-webui/extensions/sd_webui_stealth_pnginfo\n",
        "%cd /content/stable-diffusion-webui\n",
        "!git reset --hard\n",
        "!git -C /content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai reset --hard\n",
        "\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11e_sd15_ip2p_fp16.safetensors -d /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o control_v11e_sd15_ip2p_fp16.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11e_sd15_shuffle_fp16.safetensors -d /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o control_v11e_sd15_shuffle_fp16.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_canny_fp16.safetensors -d /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o control_v11p_sd15_canny_fp16.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11f1p_sd15_depth_fp16.safetensors -d /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o control_v11f1p_sd15_depth_fp16.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_inpaint_fp16.safetensors -d /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o control_v11p_sd15_inpaint_fp16.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_lineart_fp16.safetensors -d /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o control_v11p_sd15_lineart_fp16.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_mlsd_fp16.safetensors -d /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o control_v11p_sd15_mlsd_fp16.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_normalbae_fp16.safetensors -d /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o control_v11p_sd15_normalbae_fp16.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_openpose_fp16.safetensors -d /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o control_v11p_sd15_openpose_fp16.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_scribble_fp16.safetensors -d /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o control_v11p_sd15_scribble_fp16.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_seg_fp16.safetensors -d /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o control_v11p_sd15_seg_fp16.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_softedge_fp16.safetensors -d /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o control_v11p_sd15_softedge_fp16.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15s2_lineart_anime_fp16.safetensors -d /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o control_v11p_sd15s2_lineart_anime_fp16.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11f1e_sd15_tile_fp16.safetensors -d /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o control_v11f1e_sd15_tile_fp16.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/raw/main/control_v11e_sd15_ip2p_fp16.yaml -d /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o control_v11e_sd15_ip2p_fp16.yaml\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/raw/main/control_v11e_sd15_shuffle_fp16.yaml -d /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o control_v11e_sd15_shuffle_fp16.yaml\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/raw/main/control_v11p_sd15_canny_fp16.yaml -d /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o control_v11p_sd15_canny_fp16.yaml\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/raw/main/control_v11f1p_sd15_depth_fp16.yaml -d /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o control_v11f1p_sd15_depth_fp16.yaml\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/raw/main/control_v11p_sd15_inpaint_fp16.yaml -d /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o control_v11p_sd15_inpaint_fp16.yaml\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/raw/main/control_v11p_sd15_lineart_fp16.yaml -d /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o control_v11p_sd15_lineart_fp16.yaml\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/raw/main/control_v11p_sd15_mlsd_fp16.yaml -d /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o control_v11p_sd15_mlsd_fp16.yaml\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/raw/main/control_v11p_sd15_normalbae_fp16.yaml -d /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o control_v11p_sd15_normalbae_fp16.yaml\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/raw/main/control_v11p_sd15_openpose_fp16.yaml -d /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o control_v11p_sd15_openpose_fp16.yaml\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/raw/main/control_v11p_sd15_scribble_fp16.yaml -d /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o control_v11p_sd15_scribble_fp16.yaml\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/raw/main/control_v11p_sd15_seg_fp16.yaml -d /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o control_v11p_sd15_seg_fp16.yaml\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/raw/main/control_v11p_sd15_softedge_fp16.yaml -d /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o control_v11p_sd15_softedge_fp16.yaml\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/raw/main/control_v11p_sd15s2_lineart_anime_fp16.yaml -d /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o control_v11p_sd15s2_lineart_anime_fp16.yaml\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/raw/main/control_v11f1e_sd15_tile_fp16.yaml -d /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o control_v11f1e_sd15_tile_fp16.yaml\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_style_sd14v1.pth -d /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o t2iadapter_style_sd14v1.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_sketch_sd14v1.pth -d /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o t2iadapter_sketch_sd14v1.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_seg_sd14v1.pth -d /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o t2iadapter_seg_sd14v1.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_openpose_sd14v1.pth -d /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o t2iadapter_openpose_sd14v1.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_keypose_sd14v1.pth -d /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o t2iadapter_keypose_sd14v1.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_depth_sd14v1.pth -d /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o t2iadapter_depth_sd14v1.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_color_sd14v1.pth -d /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o t2iadapter_color_sd14v1.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_canny_sd14v1.pth -d /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o t2iadapter_canny_sd14v1.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_canny_sd15v2.pth -d /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o t2iadapter_canny_sd15v2.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_depth_sd15v2.pth -d /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o t2iadapter_depth_sd15v2.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_sketch_sd15v2.pth -d /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o t2iadapter_sketch_sd15v2.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_zoedepth_sd15v1.pth -d /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o t2iadapter_zoedepth_sd15v1.pth\n",
        "\n",
        "if model_name == \"Stable-Diffusion-v1-5\":\n",
        "  !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/sd15/resolve/main/v1-5-pruned-emaonly.ckpt -d /content/stable-diffusion-webui/models/Stable-diffusion -o v1-5-pruned-emaonly.ckpt\n",
        "\n",
        "if model_name == \"Anything-v3-1\":\n",
        "  !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/anything-v3.0/resolve/main/Anything-V3.0-pruned.ckpt -d /content/stable-diffusion-webui/models/Stable-diffusion -o Anything-V3.0-pruned.ckpt\n",
        "  !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.ckpt -d /content/stable-diffusion-webui/models/Stable-diffusion -o Anything-V3.0-pruned.vae.pt\n",
        "\n",
        "if model_name == \"AnyLoRA\":\n",
        "  !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/anylora/resolve/main/anyloraCheckpoint_bakedvaeFtmseFp16NOT.safetensors -d /content/stable-diffusion-webui/models/Stable-diffusion -o anyloraCheckpoint_bakedvaeFtmseFp16NOT.safetensors\n",
        "\n",
        "if model_name == \"AnimePastelDream\":\n",
        "  !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/anime-pastel-dream/resolve/main/animePastelDream_hardBakedVae.safetensors -d /content/stable-diffusion-webui/models/Stable-diffusion -o animePastelDream_hardBakedVae.safetensors\n",
        "  !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.ckpt -d /content/stable-diffusion-webui/models/Stable-diffusion -o animePastelDream_hardBakedVae.vae.pt\n",
        "\n",
        "if model_name == \"Chillout-mix\":\n",
        "  !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/chilloutmix/resolve/main/chilloutmix_NiPrunedFp32Fix.safetensors -d /content/stable-diffusion-webui/models/Stable-diffusion -o chilloutmix_NiPrunedFp32Fix.safetensors\n",
        "\n",
        "if model_name == \"OpenJourney-v4\":\n",
        "  !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/prompthero/openjourney-v4/resolve/main/openjourney-v4.ckpt -d /content/stable-diffusion-webui/models/Stable-diffusion -o openjourney-v4.ckpt\n",
        "\n",
        "!sed -i -e '''/    prepare_environment()/a\\    os.system\\(f\\\"\"\"sed -i -e ''\\\"s/dict()))/dict())).cuda()/g\\\"'' /content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/util.py\"\"\")''' /content/stable-diffusion-webui/launch.py\n",
        "!sed -i -e 's/\\\"sd_model_checkpoint\\\"\\,/\\\"sd_model_checkpoint\\,sd_vae\\,CLIP_stop_at_last_layers\\\"\\,/g' /content/stable-diffusion-webui/modules/shared.py\n",
        "\n",
        "\n",
        "dest_path = '/content/stable-diffusion-webui/models/Lora/'+trained_model_name+\".safetensors\"\n",
        "start_path = \"/content/LoRA/output/\"+trained_model_name+\".safetensors\"\n",
        "\n",
        "\n",
        "\n",
        "shutil.copyfile(start_path, dest_path)\n",
        "\n",
        "!python launch.py --listen --xformers --enable-insecure-extension-access --theme dark --gradio-queue --multiple\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "en8-QS60ZDdM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}